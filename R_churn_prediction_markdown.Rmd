---
title: "R_Churn_Telco_Kaggle"
author: "Bferrol"
date: "18/6/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Importación de datos y primeras observaciones

#### Funciones auxiliares para cargar paquetes y lista de paquetes

```{r}
prepare_packages <- function(packages){
  # Chequeamos que paquetes no estan instalados:
  non_intalled <- packages[!(packages %in% installed.packages()[, "Package"])]
  # En caso de existir alguno aún no instalado, lo instalamos:
  if (length(non_intalled)) 
    install.packages(non_intalled, dependencies = TRUE)
  # Cargamos toda la lista de paquetes:
  sapply(packages, require, character.only = TRUE)
}



packages <- c("tidyverse",
              "MASS",
              "car",
              "binr",
              "e1071",
              "caret",
              "cowplot",
              "caTools",
              "pROC",
              "ggcorrplot",
              "data.table",
              "Information",
              "rpart",
              "rpart.plot",
              "xgboost",
              "ROCR",
              "pROC",
              "h2o"
)

prepare_packages(packages)

```

Importamos el csv que fue previamente guardado en un `Azure blob storage`:
```{r}
dataset <- read.csv("https://bferrolfilesstorage.blob.core.windows.net/icemd/WA_Fn-UseC_-Telco-Customer-Churn.csv")
```

Veamos qué contiene el dataset:
```{r}
glimpse(dataset)

```

Están todos los factor booleanos en strings pero, el SeniorCitizen no. Cambiémoslo a YES/NO:
```{r}
dataset$SeniorCitizen <- as.factor(ifelse(dataset$SeniorCitizen==1, 'YES', 'NO'))
```

## Probemos un AutoML de H20 sin ninguna modificación

### Primero partimos los datos en split y test
```{r}
library(h2o)
h2o.init()

#Split data into Train/Validation/Test Sets

#split_h2o <- h2o.splitFrame(dataset.hex, c(0.6, 0.2), seed = 1234 )
#train_conv_h2o <- h2o.assign(split_h2o[[1]], "train" ) # 60%
#valid_conv_h2o <- h2o.assign(split_h2o[[2]], "valid" ) # 20%
#test_conv_h2o  <- h2o.assign(split_h2o[[3]], "test" )  # 20%

set.seed(37)
selected <- sample(1:nrow(dataset), 0.2*nrow(dataset))
train <- dataset[-selected,]
test <- dataset[selected,]
#Model
# Set names for h2o

y <- "Churn"
x <- setdiff(names(train), y)
```

```{r}
write.csv(train, file = "train.csv")
write.csv(test, file = "test.csv")

train2 = h2o.importFile("./train.csv")
test2 = h2o.importFile("./test.csv")



aml <- h2o.automl(x = x,
                  y = y,
                  training_frame = train2,
                  validation_frame = test2,
                  max_runtime_secs = 60,
                  exclude_algos = c("DeepLearning", "GLM", "DRF", "StackedEnsemble"))
```

Veamos cuál fue mejor:
```{r}

# Extract leader model
automl_leader <- aml@leader
automl_leader
```

```{r}
aml@leaderboard
```

```{r}
h2o.confusionMatrix(automl_leader)
```

Vale, vemos que el mejor modelo, nos dió una precisión del 84%. ¿Qué variables son las más importantes para que una persona haga churn o no?

```{r}
h2o.varimp_plot(automl_leader)

```





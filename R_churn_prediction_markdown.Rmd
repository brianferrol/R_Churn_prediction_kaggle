---
title: "R_Churn_dataset_Kaggle"
author: "Bferrol"
date: "18/6/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Importación de datos y primeras observaciones

#### Funciones auxiliares para cargar paquetes y lista de paquetes

```{r}
prepare_packages <- function(packages){
  # Chequeamos que paquetes no estan instalados:
  non_intalled <- packages[!(packages %in% installed.packages()[, "Package"])]
  # En caso de existir alguno aún no instalado, lo instalamos:
  if (length(non_intalled)) 
    install.packages(non_intalled, dependencies = TRUE)
  # Cargamos toda la lista de paquetes:
  sapply(packages, require, character.only = TRUE)
}



packages <- c("tidyverse",
              "MASS",
              "car",
              "binr",
              "e1071",
              "caret",
              "cowplot",
              "caTools",
              "pROC",
              "ggcorrplot",
              "data.table",
              "Information",
              "rpart",
              "rpart.plot",
              "xgboost",
              "ROCR",
              "pROC",
              "h2o",
              "dummies",
              "fastAdaboost"
)

prepare_packages(packages)
# Installation of the doSNOW parallel library with all dependencies
doInstall <- TRUE # Change to FALSE if you don't want packages installed.
toInstall <- c("doSNOW") 
if((doInstall) && (!is.element(toInstall, installed.packages()[,1])))
{
    cat("Please install required package. Select server:"); chooseCRANmirror();
    install.packages(toInstall, dependencies = c("Depends", "Imports")) 
}
# load doSnow and (parallel for CPU info) library
library(doSNOW)
library(parallel)
# For doSNOW one can increase up to 128 nodes
# Each node requires 44 Mbyte RAM under WINDOWS.
# detect cores with parallel() package
nCores <- detectCores(logical = FALSE)
cat(nCores, " cores detected.")
# detect threads with parallel()
nThreads<- detectCores(logical = TRUE)
cat(nThreads, " threads detected.")
# Create doSNOW compute cluster (try 64)
# One can increase up to 128 nodes
# Each node requires 44 Mbyte RAM under WINDOWS.
cluster = makeCluster(nThreads, type = "SOCK")
class(cluster);
# register the cluster
registerDoSNOW(cluster)
#get info
getDoParWorkers(); getDoParName();
# insert parallel computation here
        
# stop cluster and remove clients
stopCluster(cluster); print("Cluster stopped.")
# insert serial backend, otherwise error in repetetive tasks
registerDoSEQ()
# clean up a bit.
invisible(gc); remove(nCores); remove(nThreads); remove(cluster); 
```


Importamos el csv que fue previamente guardado en un `Azure blob storage`:
```{r}
dataset <- read.csv("https://bferrolfilesstorage.blob.core.windows.net/icemd/WA_Fn-UseC_-Telco-Customer-Churn.csv")
```

Veamos qué contiene el dataset:
```{r}
glimpse(dataset)

```

Están todos los factor booleanos en strings pero, el SeniorCitizen no. Cambiémoslo a YES/NO:
```{r}
dataset$SeniorCitizen <- as.factor(ifelse(dataset$SeniorCitizen==1, 'YES', 'NO'))
```

## Probemos un AutoML de H20 sin ninguna modificación

### Primero partimos los datos en split y test
```{r}
library(h2o)
h2o.init()

#Split data into Train/Validation/Test Sets

#split_h2o <- h2o.splitFrame(dataset.hex, c(0.6, 0.2), seed = 1234 )
#train_conv_h2o <- h2o.assign(split_h2o[[1]], "train" ) # 60%
#valid_conv_h2o <- h2o.assign(split_h2o[[2]], "valid" ) # 20%
#test_conv_h2o  <- h2o.assign(split_h2o[[3]], "test" )  # 20%

set.seed(37)
selected <- sample(1:nrow(dataset), 0.2*nrow(dataset))
train <- dataset[-selected,]
test <- dataset[selected,]
#Model
# Set names for h2o

y <- "Churn"
x <- setdiff(names(train), y)
```

```{r}
write.csv(train, file = "train.csv")
write.csv(test, file = "test.csv")

train2 = h2o.importFile("./train.csv")
test2 = h2o.importFile("./test.csv")



aml <- h2o.automl(x = x,
                  y = y,
                  training_frame = train2,
                  validation_frame = test2,
                  max_runtime_secs = 60,
                  exclude_algos = c("DeepLearning", "GLM", "DRF", "StackedEnsemble"))
```

Veamos cuál fue mejor:
```{r}

# Extract leader model
automl_leader <- aml@leader
automl_leader
```

```{r}
aml@leaderboard
```


```{r}
h2o.confusionMatrix(automl_leader)
```

Vale, vemos que el mejor modelo, nos dió una precisión del 84%. ¿Qué variables son las más importantes para que una persona haga churn o no?

```{r}
h2o.varimp_plot(automl_leader)

```

Las variables más importantes para predecir si una persona abandona o no, son:
* Contract: Duración de contrato.
* Tenure: Meses en la compañía (permanencia).
* Total charges: Cargos totales acumulados.



## EDA: Análisis exploratorio.

Para empezar, veamos qué porcentaje de la muestra tiene churn:
```{r}
brian_palette <- c("#6F78BD", "#EE8D47")

options(repr.plot.width = 6, repr.plot.height = 4)
dataset  %>% 
group_by(Churn) %>% 
summarise(Count = n())%>% 
mutate(percent = prop.table(Count)*100)%>%
ggplot(aes(reorder(Churn, -percent), percent), fill = Churn)+
geom_col(fill = brian_palette)+
geom_text(aes(label = sprintf("%.2f%%", percent)), hjust = 0.01,vjust = -0.5, size =3)+ 
theme_bw()+  
xlab("Churn") + 
ylab("Percent")+
ggtitle("Churn Percent")
```

```{r}
options(repr.plot.width = 16, repr.plot.height = 70)

plot_grid(ggplot(dataset, aes(x=gender,fill=Churn))+ geom_bar()
                      +scale_fill_manual(values = brian_palette),
          ggplot(dataset, aes(x=SeniorCitizen,fill=Churn))+ geom_bar(position = 'fill')
                      +scale_fill_manual(values = brian_palette),
          ggplot(dataset, aes(x=Partner,fill=Churn))+ geom_bar(position = 'fill')
                      +scale_fill_manual(values = brian_palette),
          ggplot(dataset, aes(x=Dependents,fill=Churn))+ geom_bar(position = 'fill')
                      +scale_fill_manual(values = brian_palette),
          ggplot(dataset, aes(x=PhoneService,fill=Churn))+ geom_bar(position = 'fill')
                      +scale_fill_manual(values = brian_palette),
          ggplot(dataset, aes(x=MultipleLines,fill=Churn))+ geom_bar(position = 'fill')
                      +scale_fill_manual(values = brian_palette),
          ggplot(dataset, aes(x=InternetService,fill=Churn))+ geom_bar(position = 'fill')
                      +scale_fill_manual(values = brian_palette),
          ggplot(dataset, aes(x=OnlineSecurity,fill=Churn))+ geom_bar(position = 'fill')
                      +scale_fill_manual(values = brian_palette),
          ggplot(dataset, aes(x=OnlineBackup,fill=Churn))+ geom_bar(position = 'fill')
                      +scale_fill_manual(values = brian_palette),
          ggplot(dataset, aes(x=DeviceProtection,fill=Churn))+ geom_bar(position = 'fill')
                      +scale_fill_manual(values = brian_palette),
          ggplot(dataset, aes(x=StreamingMovies,fill=Churn))+ geom_bar(position = 'fill')
                      +scale_fill_manual(values = brian_palette),
          ggplot(dataset, aes(x=StreamingTV,fill=Churn))+ geom_bar(position = 'fill')
                      +scale_fill_manual(values = brian_palette),
          ggplot(dataset, aes(x=Contract,fill=Churn))+ geom_bar(position = 'fill')
                      +scale_fill_manual(values = brian_palette),
          ggplot(dataset, aes(x=PaperlessBilling,fill=Churn))+ geom_bar(position = 'fill')
                      +scale_fill_manual(values = brian_palette),
          ggplot(dataset, aes(x=PaymentMethod,fill=Churn))+ geom_bar(position = 'fill')
                      +scale_fill_manual(values = brian_palette)
          
          +theme_bw()+scale_x_discrete(labels = function(x) str_wrap(x, width = 1)),
          align = "v", ncol=3)
```

Podemos ver, por ejemplo:
* Las personas mayores son más propensas a abandonar la compañía.
* Las personas con dependientes, son menos propensas a abandonar la compañía.
* Las personas con múltiples líneas, tienen una ligera mayor proporción de abandonar.


```{r}
dataset %>%
  ggplot(aes(x=TotalCharges,fill=Churn))+   geom_density(alpha=0.8)+scale_fill_manual(values=brian_palette)+labs(title='Distribución de TotalCharges por churn' )
```

Podemos ver que a menores cargos acumulados, mayor proporción de abandonadores, y a medida que este valor crece, bajan los abandonadores. Se podría concluír que los clientes más fieles son los que están hace más años con la compañía.

Comprobémoslo:

```{r}
dataset %>%
  ggplot(aes(x=tenure,fill=Churn))+ geom_density(alpha=0.8)+scale_fill_manual(values=brian_palette)+labs(title='Distribución de TotalCharges por churn' )
```

Efectivamente, los clientes nuevos tienden a abandonar con más frecuencia que los que ya llevan un tiempo relativo en la empresa.

Hagamos un `boxplot` para ver las distribuciones de las variables continuas:

```{r}
library(GGally)

# Identificamos las variables continuas
class_vars <- sapply(dataset, class)
num_vars <- dataset[class_vars=="numeric"]
int_vars_names <- names(dataset)[class_vars=="integer"]

dataset[int_vars_names,] <- sapply(dataset[int_vars_names,], as.numeric)

num_vars <- dataset[class_vars=="numeric" | class_vars=="integer"]

ggpairs(num_vars, 
        title="Distribución de variables continuas",
        colours=brian_palette)

```

Podemos ver que existe cierta relación directa entre los cargos totales y el precio mensual.

```{r}
correlations <- cor(num_vars, use = "complete.obs")
correlations
ggcorrplot(correlations,
           type = "lower",
           title = "Correlación de variables numéricas",
           lab = TRUE,
           lab_size = 3,
           colors = c("white", "orange", "brown"))

```


```{r}
class_vars
```



## Preparación de datos

Veamos cuántos datos nulos tenemos:

```{r}
missing_data <- dataset %>% summarise_all(funs(sum(is.na(.))))
missing_data
```

¿cuáles son estos 11 casos que tienen `TotalCharges = NA`?
```{r}
nans = dataset[is.na(dataset$TotalCharges),]
nans
```

Suena lógico, tienen `TotalCharges` nulo, porque su `tenure` es 0, quiere decir que todavía no pagaron su primera cuota.

Esto lleva a preguntarme, ¿merece la pena tener estos casos para hacer una predicción? ¿Tienen información histórica suficiente como para aportar a nuestro modelo o más bien son outliers? ¿los rellenamos con 0 o los quitamos?

Veamos un boxplot de la columna `TotalCharges`:

```{r}
p <- ggplot(dataset, aes(x=Churn, y=tenure)) + 
  geom_boxplot()
p
```

Si bien el rango intercuartil de `tenure` para los abandonadores es más bajo, se decide quitar estos 11 casos, dado que no merecería la pena meter en el modelo a clientes que todavía no poseen información mínima histórica con la compañía.

```{r}
clean_dataset = dataset[!(is.na(dataset$TotalCharges)),]
clean_dataset
```

### Information value:


```{r}
#dataset$Churn <- as.numeric(ifelse(dataset$Churn=="YES", 1, 0))

clean_dataset$Churn <- as.numeric(ifelse(clean_dataset$Churn == "Yes", 1, 0))

iv_ds <- create_infotables(data=clean_dataset,
                           y="Churn")

iv_summary <- iv_ds$Summary
iv_summary <- iv_summary[order(iv_summary$IV), ]
iv_summary$Variable <- factor(iv_summary$Variable, levels=iv_summary$Variable)

ggplot(iv_summary, aes(x=Variable, y=IV, fill = IV))+
  coord_flip() +
  scale_fill_gradient(low = "grey", high = "green") +
  geom_bar(stat = "identity")

```
  

WOE segun la variable más importante `Contract`:


```{r}
ggplot(iv_ds$Tables$Contract, aes(x=Contract, y=WOE, fill = WOE))+
  scale_fill_gradient(low = "red", high = "green") +
  geom_bar(stat = "identity")
```

¿Y según `tenure`?:


```{r}
ggplot(iv_ds$Tables$tenure, aes(x=tenure, y=WOE, fill = WOE))+
  scale_fill_gradient(low = "red", high = "green") +
  geom_bar(stat = "identity")
```




## Preprocessing:

Hay variables categóricas que tienen el mismo valor, por lo tanto hay que modificarlas para notener misma información en dos variables si las pasamos a dummies:

```{r}
clean_dataset <- data.frame(lapply(clean_dataset, function(x) {
                  gsub("No internet service", "No", x)}))
clean_dataset <- data.frame(lapply(clean_dataset, function(x) {
                  gsub("No phone service", "No", x)}))
```

`tenure` es una variable continua, pero con valores absolutos. Para evitar problemas de ordinalidad, la clasificaremos en rangos:

```{r}
group_tenure <- function(tenure){
    if (tenure >= 0 & tenure <= 12){
        return('0-12 Month')
    }else if(tenure > 12 & tenure <= 24){
        return('12-24 Month')
    }else if (tenure > 24 & tenure <= 48){
        return('24-48 Month')
    }else if (tenure > 48 & tenure <=60){
        return('48-60 Month')
    }else if (tenure > 60){
        return('> 60 Month')
    }
}


clean_dataset$tenure <- as.numeric(clean_dataset$tenure)
clean_dataset$tenure_group <- sapply(clean_dataset$tenure,group_tenure)
clean_dataset$tenure_group <- as.factor(clean_dataset$tenure_group)

clean_dataset$tenure <- NULL
```




```{r}
df <- clean_dataset[,names(clean_dataset) != "customerID"]



df$MonthlyCharges <- as.numeric(df$MonthlyCharges)
df$TotalCharges <- as.numeric(df$TotalCharges)

class_vars <- sapply(df, class)

cat_vars <- df[,class_vars=="factor"]
cat_vars$Churn <- NULL

class_vars

```



```{r}
library("fastDummies")

Dummies <- dummy_cols(df, select_columns = names(cat_vars), remove_first_dummy = TRUE)

df <- Dummies[,!names(Dummies) %in% names(cat_vars)]

df$Churn <- as.factor(df$Churn)
```


## Modelos de clasificación:

Primero hacemos un split de las variables:


```{r}
library("caret")

seed <- 12345 
  
set.seed(seed)

trainIndex <- createDataPartition(df$Churn, p = .80, 
                                  list = FALSE, 
                                  times = 1)
head(trainIndex)
```

Separamos el dataframe en muestras de entrenamiento y de evaluación de resultados:

```{r}
Train <- df[ trainIndex,]
Test  <- df[-trainIndex,]

```

```{r}
head(Train)
```

### Regresión logística

```{r}

fitControl <- trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = 10,
                           ## repeated ten times
                           repeats = 10)


## Logistic regression
lreg<-train(Churn ~ ., data = Train,
            method="glm",
            family=binomial(),
            trControl=fitControl)
summary(lreg)

```

Vamos a sacar variables que tienen el p-value muy alto o mucho rango de error:

```{r}
# Creamos el nuevo Train y test:
Train2 <-  Train
Train2$MultipleLines_Yes <- NULL
Train2$Dependents_Yes <- NULL

Test2 <- Test
Test2$MultipleLines_Yes <- NULL
Test2$Dependents_Yes <- NULL


#Probamos nuevo modelo:

lreg2 <-train(Churn ~ ., data = Train2,
            method="glm",
            family=binomial(),
            trControl=fitControl)

lreg2
summary(lreg2)


```

Veamos la matriz de confusión para este modelo:
```{r}

model_glm_predict <- predict(lreg2,Test2)
confusionMatrix(model_glm_predict,Test2$Churn)

```

No resultó siendo un modelo muy bueno, ya que podemos ver que existe una gran cantidad de falsos positivos y hay bastantes abandonadores que no los reconoce.



### Adaboost

```{r}
library(fastAdaboost)


ada = adaboost(Churn~.,
               Train2, 
               nIter = 40)

ada
summary(ada)
```

Veamos los resultados:
```{r}
model_ada_predict <- predict(ada,newdata =  Test2)

confusionMatrix(model_ada_predict$class, Test2$Churn)


```

Con este segundo modelo, obtenemos un peor resultado, en cuanto a accuracy y falsos negativos.


